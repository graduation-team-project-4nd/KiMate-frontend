// File: MultiAnalyzer.kt
package com.example.kioskassistapp.ocr

import android.content.ContentValues.TAG
import android.content.Context
import android.graphics.Bitmap
import android.graphics.BitmapFactory
import android.graphics.Matrix
import android.graphics.PointF
import android.graphics.Rect
import android.os.SystemClock
import android.util.Log
import androidx.annotation.VisibleForTesting
import androidx.annotation.OptIn
import androidx.camera.core.ExperimentalGetImage
import androidx.camera.core.ImageAnalysis
import androidx.camera.core.ImageProxy
import androidx.camera.core.impl.utils.MatrixExt.postRotate
import com.google.mlkit.vision.common.InputImage
import com.google.mlkit.vision.text.TextRecognition
import com.google.mlkit.vision.text.korean.KoreanTextRecognizerOptions
import com.google.mediapipe.framework.image.BitmapImageBuilder
import com.google.mediapipe.framework.image.MPImage
import com.google.mediapipe.tasks.core.BaseOptions
import com.google.mediapipe.tasks.core.Delegate
import com.google.mediapipe.tasks.vision.core.RunningMode
import com.google.mediapipe.tasks.vision.handlandmarker.HandLandmarker
import com.google.mediapipe.tasks.vision.handlandmarker.HandLandmarkerResult
import java.util.concurrent.CountDownLatch
import java.util.concurrent.Executors
import java.util.concurrent.TimeUnit

class MultiAnalyzer(
    private val context: Context,  // ğŸ‘ˆ Context for HandLandmarker
    /**
     * ëª¨ë“  ë¶„ì„(OCR, Pose)ì´ ì™„ë£Œë˜ì—ˆì„ ë•Œ í˜¸ì¶œë˜ëŠ” ë‹¨ì¼ ì½œë°±
     * @param textsAndBoxes (í…ìŠ¤íŠ¸ String, ë°•ìŠ¤ Rect) ìŒì˜ ë¦¬ìŠ¤íŠ¸
     * @param fingerTip ê°ì§€ëœ ì†ê°€ë½ ì¢Œí‘œ (ì—†ìœ¼ë©´ null)
     * @param imageWidth ë¶„ì„ì— ì‚¬ìš©ëœ ì´ë¯¸ì§€ì˜ ë„ˆë¹„
     * @param imageHeight ë¶„ì„ì— ì‚¬ìš©ëœ ì´ë¯¸ì§€ì˜ ë†’ì´
     */
    private val onAnalysisComplete: (List<Pair<String, Rect>>, PointF?, Int, Int) -> Unit
) : ImageAnalysis.Analyzer {

    private val executor = Executors.newFixedThreadPool(2)
    private val TAG = "MultiAnalyzer"

    private val ocrRecognizer = TextRecognition.getClient(KoreanTextRecognizerOptions.Builder().build())

    // â–¼â–¼â–¼ [í†µí•©] HandLandmarkerHelper (ì œê³µëœ ì½”ë“œ ê¸°ë°˜, IMAGE modeë¡œ ì„¤ì •)
    private val handLandmarkerHelper = HandLandmarkerHelper(
        minHandDetectionConfidence = 0.5f,
        minHandTrackingConfidence = 0.5f,
        minHandPresenceConfidence = 0.5f,
        maxNumHands = 1,
        currentDelegate = HandLandmarkerHelper.DELEGATE_CPU,  // GPUëŠ” í…ŒìŠ¤íŠ¸ í›„ ë³€ê²½
        runningMode = RunningMode.IMAGE,
        context = context
    )
    // â–²â–²â–²

    // â–¼â–¼â–¼ ë§ˆì§€ë§‰ ë¶„ì„ ì‹œê°„ì„ ì €ì¥í•  ë³€ìˆ˜ ì¶”ê°€ â–¼â–¼â–¼
    private var lastAnalysisTime = 0L

    @OptIn(ExperimentalGetImage::class)
    override fun analyze(imageProxy: ImageProxy) {
        // â–¼â–¼â–¼ 3ì´ˆ ê°„ê²© ì²´í¬ ë¡œì§ ì¶”ê°€ â–¼â–¼â–¼
        val currentTime = System.currentTimeMillis()
        if (currentTime - lastAnalysisTime < 3000) { // 3000ms = 3ì´ˆ
            imageProxy.close() // 3ì´ˆê°€ ì•ˆ ì§€ë‚¬ìœ¼ë©´ í”„ë ˆì„ ë‹«ê³  ì¦‰ì‹œ ì¢…ë£Œ
            return
        }
        // 3ì´ˆê°€ ì§€ë‚¬ìœ¼ë©´, í˜„ì¬ ì‹œê°„ì„ ë§ˆì§€ë§‰ ë¶„ì„ ì‹œê°„ìœ¼ë¡œ ê¸°ë¡
        lastAnalysisTime = currentTime
        // â–²â–²â–²
        val mediaImage = imageProxy.image
        if (mediaImage == null) {
            imageProxy.close()
            return
        }

        val rotation = imageProxy.imageInfo.rotationDegrees
        val inputImage = InputImage.fromMediaImage(mediaImage, rotation)

        // â–¼â–¼â–¼ ì´ë¯¸ì§€ í¬ê¸°ë¥¼ ì½œë°±ìœ¼ë¡œ ì „ë‹¬í•˜ê¸° ìœ„í•´ ì €ì¥ â–¼â–¼â–¼
        val imageWidth = inputImage.width
        val imageHeight = inputImage.height
        // â–²â–²â–²

        val latch = CountDownLatch(2)

        // ê²°ê³¼ë¥¼ ë‹´ì„ ì„ì‹œ ë³€ìˆ˜
        val detectedTexts = mutableListOf<Pair<String, Rect>>()
        var fingerTip: PointF? = null

        executor.execute {
            try {
                // ğŸ”¹ OCR Task (ê¸°ì¡´ ê·¸ëŒ€ë¡œ)
                ocrRecognizer.process(inputImage)
                    .addOnSuccessListener { visionText ->
                        for (block in visionText.textBlocks) {
                            block.boundingBox?.let { box ->
                                // í…ìŠ¤íŠ¸ì™€ Rectë¥¼ Pairë¡œ ë¬¶ì–´ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                                detectedTexts.add(block.text to box)
                                Log.d(TAG, "Detected Text: '${block.text}' at $box")
                            }
                        }
                    }
                    .addOnFailureListener { Log.e(TAG, "OCR Failure", it) }
                    .addOnCompleteListener { latch.countDown() }

                // ğŸ”¹ Hand Task (HandLandmarkerHelper ì‚¬ìš©)
                val bitmap = imageProxy.toBitmap()  // ğŸ‘ˆ Extension ì‚¬ìš©
                val matrix = Matrix().apply {
                    postRotate(rotation.toFloat())  // ImageProxy rotation ì ìš©
                    // isFrontCameraë©´ í”Œë¦½ ì¶”ê°€: postScale(-1f, 1f, bitmap.width / 2f, bitmap.height / 2f)
                }
                val rotatedBitmap = Bitmap.createBitmap(
                    bitmap, 0, 0, bitmap.width, bitmap.height, matrix, true
                )
                val resultBundle = handLandmarkerHelper.detectImage(rotatedBitmap)  // detectImage í˜¸ì¶œ
                if (resultBundle != null && resultBundle.results.isNotEmpty()) {
                    val handResult = resultBundle.results[0]  // ì²« ë²ˆì§¸ ì† ê²°ê³¼
                    val landmarks = handResult.landmarks()  // List<NormalizedLandmark>
                    if (landmarks.isNotEmpty()) {
                        // ì˜¤ë¥¸ì† ê²€ì§€ ë (index 8: RIGHT_INDEX_FINGER_TIP)
                        val rightIndexLandmark = landmarks[0][8]  // landmarks[hand][landmarkIndex]
                        // Normalized â†’ Pixel ë³€í™˜ (confidence ì²´í¬ ì œê±°)
                        val x = rightIndexLandmark.x() * imageWidth
                        val y = rightIndexLandmark.y() * imageHeight
                        fingerTip = PointF(x, y)
                        Log.d(TAG, "Detected Finger Tip: ($x, $y)")
                    } else {
                        Log.w(TAG, "No landmarks detected")
                    }
                } else {
                    Log.w(TAG, "No hand results")
                }
                latch.countDown()  // ğŸ‘ˆ ë™ê¸° detectì´ë‹ˆ ì§ì ‘ countDown()

            } catch (e: Exception) {
                Log.e(TAG, "Analysis Error", e)
                latch.countDown()
                latch.countDown()
            }

            // ğŸ”¹ ëª¨ë“  Task ì™„ë£Œ ëŒ€ê¸°
            try {
                if (latch.await(7, TimeUnit.SECONDS)) {  // Hand Landmarker ë¬´ê±°ì›€ â†’ 7ì´ˆ
                    // â–¼â–¼â–¼ ëª¨ë“  ê²°ê³¼ë¥¼ ë‹¨ì¼ ì½œë°±ìœ¼ë¡œ ì „ë‹¬ â–¼â–¼â–¼
                    onAnalysisComplete(detectedTexts, fingerTip, imageWidth, imageHeight)
                    Log.d("OverlayDebug", "Original fingerPoint: $fingerTip (image: ${imageWidth}x${imageHeight})")
                } else {
                    Log.w(TAG, "Timeout on tasks")
                }
            } catch (e: InterruptedException) {
                Log.e(TAG, "Latch await interrupted", e)
            } finally {
                imageProxy.close()
                // Bitmap í•´ì œ (ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€)
                // bitmap?.recycle()  // í•„ìš” ì‹œ ì¶”ê°€
            }
        }
    }

    // â–¼â–¼â–¼ [ì„ë² ë“œ] HandLandmarkerHelper í´ë˜ìŠ¤ (ì œê³µëœ ì½”ë“œ ê¸°ë°˜, Listener ì œê±° â€“ IMAGE modeë¼ ë¶ˆí•„ìš”)
    private class HandLandmarkerHelper(
        var minHandDetectionConfidence: Float = DEFAULT_HAND_DETECTION_CONFIDENCE,
        var minHandTrackingConfidence: Float = DEFAULT_HAND_TRACKING_CONFIDENCE,
        var minHandPresenceConfidence: Float = DEFAULT_HAND_PRESENCE_CONFIDENCE,
        var maxNumHands: Int = DEFAULT_NUM_HANDS,
        var currentDelegate: Int = DELEGATE_CPU,
        var runningMode: RunningMode = RunningMode.IMAGE,
        val context: Context
    ) {
        private var handLandmarker: HandLandmarker? = null
        init {
            setupHandLandmarker()
        }

        fun clearHandLandmarker() {
            handLandmarker?.close()
            handLandmarker = null
        }

        fun isClose(): Boolean = handLandmarker == null

        fun setupHandLandmarker() {
            val baseOptionBuilder = BaseOptions.builder()
            when (currentDelegate) {
                DELEGATE_CPU -> baseOptionBuilder.setDelegate(Delegate.CPU)
                DELEGATE_GPU -> baseOptionBuilder.setDelegate(Delegate.GPU)
            }
            baseOptionBuilder.setModelAssetPath(MP_HAND_LANDMARKER_TASK)
            try {
                val baseOptions = baseOptionBuilder.build()
                val optionsBuilder = HandLandmarker.HandLandmarkerOptions.builder()
                    .setBaseOptions(baseOptions)
                    .setMinHandDetectionConfidence(minHandDetectionConfidence)
                    .setMinTrackingConfidence(minHandTrackingConfidence)
                    .setMinHandPresenceConfidence(minHandPresenceConfidence)
                    .setNumHands(maxNumHands)
                    .setRunningMode(runningMode)
                val options = optionsBuilder.build()
                handLandmarker = HandLandmarker.createFromOptions(context, options)
            } catch (e: Exception) {
                Log.e(TAG, "Hand Landmarker failed to initialize: ${e.message}")
            }
        }

        // IMAGE modeìš© detectImage (ì œê³µëœ ì½”ë“œ ê¸°ë°˜)
        fun detectImage(image: Bitmap): ResultBundle? {
            if (runningMode != RunningMode.IMAGE) {
                throw IllegalArgumentException("RunningMode must be IMAGE")
            }
            val startTime = SystemClock.uptimeMillis()
            val mpImage = BitmapImageBuilder(image).build()
            handLandmarker?.detect(mpImage)?.also { landmarkResult ->
                val inferenceTimeMs = SystemClock.uptimeMillis() - startTime
                return ResultBundle(
                    listOf(landmarkResult),
                    inferenceTimeMs,
                    image.height,
                    image.width
                )
            }
            return null
        }

        companion object {
            private const val MP_HAND_LANDMARKER_TASK = "hand_landmarker.task"  // ğŸ‘ˆ assets/ íŒŒì¼
            const val DELEGATE_CPU = 0
            const val DELEGATE_GPU = 1
            const val DEFAULT_HAND_DETECTION_CONFIDENCE = 0.5f
            const val DEFAULT_HAND_TRACKING_CONFIDENCE = 0.5f
            const val DEFAULT_HAND_PRESENCE_CONFIDENCE = 0.5f
            const val DEFAULT_NUM_HANDS = 1
        }

        data class ResultBundle(
            val results: List<HandLandmarkerResult>,
            val inferenceTime: Long,
            val inputImageHeight: Int,
            val inputImageWidth: Int
        )
    }
    // â–²â–²â–²
}